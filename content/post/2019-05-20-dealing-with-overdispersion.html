---
title: Dealing with Overdispersion
author: Chris Mainey
date: '2019-10-18'
slug: dealing-with-overdispersion
categories: 
- ovedispersion
- R
draft: true
tags: 
- R
- overdispersion
- count data
- mixed models
summary: Overdispersion is a phenomenon affecting count data.  This post explains what it is, and how to adjust for it.
bibliography: ../../content/post/references.bib
image:
  caption: ''
  focal_point: ''
math: true
output:
  blogdown::html_page:
    toc: true
    number_sections: true
    toc_depth: 1
---


<div id="TOC">
<ul>
<li><a href="#what-is-overdispersion"><span class="toc-section-number">1</span> What is overdispersion?</a></li>
<li><a href="#exammple"><span class="toc-section-number">2</span> Exammple:</a></li>
</ul>
</div>

<div id="what-is-overdispersion" class="section level1">
<h1><span class="header-section-number">1</span> What is overdispersion?</h1>
<p>This post discusses ‘overdispersion’ (‘OD’ in this post), a term commonly seen when using count data (such as the NHS mortality indicator <a href="www.digital.nhs.uk/SHMI">SHMI</a>. I will discuss what it is, how it affects our data and our interpretations as well as some options for dealing with it. It is related to an earlier post on <a href="https://mainard.co.uk/post/introduction-to-funnel-plots/">Funnel plots</a>, as these plot need adjustment in the presence of OD. It will help explain the adjustment used in that post, as well as other (and in my opinion, better) approaches.</p>
<p>To understand the context, we have to think about count data. Count data are real, numeric values (sometimes referred to as ‘discrete’), they can only be whole numbers. They are bounded at (cannot go below) zero. So we can have a count of 2 or 3, but not 2.5, and we can have 0 or more events, but not -1 events.</p>
<p>These properties of counts mean that they are naturally skewed (the distribution is not symetrical) when the mean count is low. They are therefore not normally distributed (see below).</p>
<pre class="r"><code>set.seed(123)
dist &lt;- data.frame(Normal1 = rnorm(1000, 1, 2),
                   Normal2 = rnorm(1000, 2, 2),
                   Normal5 = rnorm(1000, 5, 2),
                   Normal10 = rnorm(1000, 10, 2),
                   Poisson1 = rpois(1000, 1),
                   Poisson2 = rpois(1000, 2),
                   Poisson5 = rpois(1000, 5),
                   Poisson10 = rpois(1000, 10)
)

library(ggplot2)                   
library(tidyr)

dist&lt;-gather(dist, key=&quot;key&quot;, value=&quot;value&quot;)
dist$key &lt;- factor(dist$key, ordered = TRUE)
dist$key &lt;- forcats::fct_inorder(dist$key)
dist$dist &lt;- as.integer(stringr::str_detect(dist$key, &quot;Normal&quot;))

ggplot(dist, aes(x=value, col=key, fill = key))+
  geom_histogram(alpha=0.5,position = &quot;identity&quot;)+
  facet_wrap(~dist)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="/post/2019-05-20-dealing-with-overdispersion_files/figure-html/distributions-1.png" width="672" /></p>
<p>They are commonly modelled using the Poisson distribution. Forgive the mathsy description, but it’s the best way:</p>
<p><span class="math display">\[ Pr(Y = y) = \frac{\mu^y e^-\mu^\lambda }{y!}\]</span></p>
<p>When transformed into a Poisson regression, we end up modelling the expected count <span class="math inline">\(\mu\)</span>, ususllay through a log transformation:</p>
<p><span class="math display">\[ ln(\mu) = \alpha + \beta x\]</span></p>
<p>In the equation above we have no separate error term, and size of <span class="math inline">\(\mu\)</span> is also it’s variance.
This means that the variance cannot be different. Unless we have perfectly behaved Poisson data, and few things in real life are perfectly behaved, our variance will not be quite right. The upshot of this is that the assessment of parameter signficance, and model accuracy will be affected.</p>
<p>We usually observe ‘overdispersion’, where there is more variance in our data than the Poisson distribtuion assumes. This means that we underestiamte our error, and overestimate the signficance of parameters. There are a lot of different way to deal with this. Our choice of technique depends on our assumptions, the data generating mechinsm and what we want to use the model for.</p>
<p>Overdispersion generally arises from one of the following:</p>
<ul>
<li>Insufficent predictors in the model (bad model)</li>
<li>Poorly parameterised model (bad preparation)</li>
<li>Aggregation of data</li>
<li>Correlations in data / violations of the ‘independence’ assumption</li>
</ul>
<p>1 &amp; 2 can be solved by having more, and better quality data. Sometimes this is possible, but often it’s not. Aggreagation is sometimes neccisary because we don’t have the underlying data, or we are building panel models based on counts etc.</p>
</div>
<div id="exammple" class="section level1">
<h1><span class="header-section-number">2</span> Exammple:</h1>
<p>I’m going to use the <code>NHSRdatasets</code> package for this post, and build a regression model on the Length-of-Stay field in the <code>LOS_model</code> data set. we can then test if it is over dispersed. Firstly, lets visulaise the distribution before we build our model.</p>
<pre class="r"><code>install.packages(&quot;NHSRdatasets&quot;)
library(NHSRdatasets)</code></pre>
<pre class="r"><code>data(&quot;LOS_model&quot;)

Hmisc::describe(LOS_model)</code></pre>
<pre><code>## LOS_model 
## 
##  5  Variables      300  Observations
## --------------------------------------------------------------------------------
## ID 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      300        0      300        1    150.5    100.3    15.95    30.90 
##      .25      .50      .75      .90      .95 
##    75.75   150.50   225.25   270.10   285.05 
## 
## lowest :   1   2   3   4   5, highest: 296 297 298 299 300
## --------------------------------------------------------------------------------
## Organisation 
##        n  missing distinct 
##      300        0       10 
## 
## lowest : Trust1  Trust2  Trust3  Trust4  Trust5 
## highest: Trust6  Trust7  Trust8  Trust9  Trust10
##                                                                           
## Value       Trust1  Trust2  Trust3  Trust4  Trust5  Trust6  Trust7  Trust8
## Frequency       30      30      30      30      30      30      30      30
## Proportion     0.1     0.1     0.1     0.1     0.1     0.1     0.1     0.1
##                           
## Value       Trust9 Trust10
## Frequency       30      30
## Proportion     0.1     0.1
## --------------------------------------------------------------------------------
## Age 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      300        0       88        1    50.66    32.14     9.00    13.00 
##      .25      .50      .75      .90      .95 
##    24.00    54.00    75.25    88.00    92.00 
## 
## lowest :  5  6  7  8  9, highest: 91 92 93 94 95
## --------------------------------------------------------------------------------
## LOS 
##        n  missing distinct     Info     Mean      Gmd      .05      .10 
##      300        0       16    0.986    4.937    3.939        1        1 
##      .25      .50      .75      .90      .95 
##        2        4        7       10       12 
## 
## lowest :  1  2  3  4  5, highest: 12 13 14 15 18
##                                                                             
## Value          1     2     3     4     5     6     7     8     9    10    11
## Frequency     49    48    42    29    26    18    18    14    13    15    12
## Proportion 0.163 0.160 0.140 0.097 0.087 0.060 0.060 0.047 0.043 0.050 0.040
##                                         
## Value         12    13    14    15    18
## Frequency      7     2     2     3     2
## Proportion 0.023 0.007 0.007 0.010 0.007
## --------------------------------------------------------------------------------
## Death 
##        n  missing distinct     Info      Sum     Mean      Gmd 
##      300        0        2    0.436       53   0.1767   0.2919 
## 
## --------------------------------------------------------------------------------</code></pre>
<pre class="r"><code>library(ggplot2)
ggplot(LOS_model, aes(LOS))+
  geom_histogram(bins=15, fill=&quot;dodgerblue2&quot;, alpha=0.6, col=1)+
  geom_vline(aes(xintercept=median(LOS)), col=&quot;red&quot;)+
  ggtitle(&quot;Histogram of Length of Stay in &#39;LOS_model&#39;&quot;)</code></pre>
<p><img src="/post/2019-05-20-dealing-with-overdispersion_files/figure-html/load-1.png" width="672" /></p>
<p>So we have a skewed distribution, with the median represente dby the red line. Lets build a Poisson model next:</p>
<pre class="r"><code>glm1 &lt;- glm(LOS ~ Age * Death, data=LOS_model, family=&quot;poisson&quot;)

summary(glm1)</code></pre>
<pre><code>## 
## Call:
## glm(formula = LOS ~ Age * Death, family = &quot;poisson&quot;, data = LOS_model)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.4929  -0.9039  -0.1069   0.7589   3.3681  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.514456   0.078345   6.567 5.15e-11 ***
## Age          0.018097   0.001169  15.479  &lt; 2e-16 ***
## Death        1.491162   0.140864  10.586  &lt; 2e-16 ***
## Age:Death   -0.020209   0.002187  -9.240  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 752.23  on 299  degrees of freedom
## Residual deviance: 459.77  on 296  degrees of freedom
## AIC: 1429
## 
## Number of Fisher Scoring iterations: 5</code></pre>
We can test for OD, using the ratio of the sum of the squared Pearson residuals over the degrees of freedom. If this value is 1, then the variance is as expected (‘equidispersion’), but if it is &gt;1, then we have OD, and this value can be interpreted as a dispersion ratio (
</div>
